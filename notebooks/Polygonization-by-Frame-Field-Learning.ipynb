{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1b87db2",
   "metadata": {},
   "source": [
    "[9:50 AM] Yuliya Tarabalka\n",
    "https://github.com/Lydorn/Polygonization-by-Frame-Field-Learning\n",
    "GitHub - Lydorn/Polygonization-by-Frame-Field-Learning: This repository contains the code for our fast polygonal building extraction from overhead images pipeline.\n",
    "This repository contains the code for our fast polygonal building extraction from overhead images pipeline. - Lydorn/Polygonization-by-Frame-Field-Learning\n",
    " \n",
    "[9:54 AM] Yuliya Tarabalka\n",
    "could you pls see : 1) if it would be easy to integrate this model within giQ? 2) can we run comparison of our model and this model on a few Inria benchmark images and some Pleaides neo images?\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7333adaa",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db0fa413",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T06:39:52.400962Z",
     "start_time": "2024-08-23T06:39:52.386123Z"
    }
   },
   "outputs": [],
   "source": [
    "#! mkdir git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d04c06a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T06:39:54.315396Z",
     "start_time": "2024-08-23T06:39:54.310781Z"
    }
   },
   "outputs": [],
   "source": [
    "#! cd git && git clone --recursive --jobs 8 https://github.com/younes-abid/Polygonization-by-Frame-Field-Learning.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bb9b8d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T06:39:54.723137Z",
     "start_time": "2024-08-23T06:39:54.718012Z"
    }
   },
   "outputs": [],
   "source": [
    "#! cd git && git checkout develop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69d4165b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T06:39:55.338311Z",
     "start_time": "2024-08-23T06:39:55.333945Z"
    }
   },
   "outputs": [],
   "source": [
    "# conda create --name building-detection python==3.10.8 -y\n",
    "# conda activate building-detection\n",
    "# cd git/Polygonization-by-Frame-Field-Learning/ && pip install -r requirements.txt\n",
    "# cd git/Polygonization-by-Frame-Field-Learning/ && bash setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c22a92b",
   "metadata": {},
   "source": [
    "# Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66474d70",
   "metadata": {},
   "source": [
    "https://drive.google.com/drive/folders/19yqseUsggPEwLFTBl04CmGmzCZAIOYhy?usp=sharing\n",
    "\n",
    "https://project.inria.fr/aerialimagelabeling/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f75dc0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baaad489-9508-4504-b2e2-f209391713cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/younes.abid/Desktop/inference_test/train/building_detection/git/Polygonization-by-Frame-Field-Learning/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b591a05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T06:41:03.267931Z",
     "start_time": "2024-08-23T06:40:54.087145Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: main.py [-h] [--in_filepath [IN_FILEPATH ...]]\n",
      "               [--out_dirpath OUT_DIRPATH] [-c CONFIG]\n",
      "               [--dataset_params DATASET_PARAMS] [-r RUNS_DIRPATH]\n",
      "               [--run_name RUN_NAME] [--new_run]\n",
      "               [--init_run_name INIT_RUN_NAME] [--samples SAMPLES]\n",
      "               [-b BATCH_SIZE] [--eval_batch_size EVAL_BATCH_SIZE]\n",
      "               [-m {train,eval,eval_coco}] [--fold [{train,val,test} ...]]\n",
      "               [--max_epoch MAX_EPOCH] [--eval_patch_size EVAL_PATCH_SIZE]\n",
      "               [--eval_patch_overlap EVAL_PATCH_OVERLAP]\n",
      "               [--master_addr MASTER_ADDR] [--master_port MASTER_PORT] [-n N]\n",
      "               [-g GPUS] [-nr NR]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --in_filepath [IN_FILEPATH ...]\n",
      "                        For launching prediction on several images, use this\n",
      "                        argument to specify their paths.If --out_dirpath is\n",
      "                        specified, prediction outputs will be saved there..If\n",
      "                        --out_dirpath is not specified, predictions will be\n",
      "                        saved next to inputs.Make sure to also specify the\n",
      "                        run_name of the model to use for prediction.\n",
      "  --out_dirpath OUT_DIRPATH\n",
      "                        Path to the output directory of prediction when using\n",
      "                        the --in_filepath option to launch prediction on\n",
      "                        several images.\n",
      "  -c CONFIG, --config CONFIG\n",
      "                        Name of the config file, excluding the .json file\n",
      "                        extension.\n",
      "  --dataset_params DATASET_PARAMS\n",
      "                        Allows to overwrite the dataset_params in the config\n",
      "                        file. Accepts a path to a .json file.\n",
      "  -r RUNS_DIRPATH, --runs_dirpath RUNS_DIRPATH\n",
      "                        Directory where runs are recorded (model saves and\n",
      "                        logs).\n",
      "  --run_name RUN_NAME   Name of the run to use.That name does not include the\n",
      "                        timestamp of the folder name: <run_name> | <yyyy-mm-dd\n",
      "                        hh:mm:ss>.\n",
      "  --new_run             Train from scratch (when True) or train from the last\n",
      "                        checkpoint (when False)\n",
      "  --init_run_name INIT_RUN_NAME\n",
      "                        This is the run_name to initialize the weights from.If\n",
      "                        None, weights will be initialized randomly.This is a\n",
      "                        single word, without the timestamp.\n",
      "  --samples SAMPLES     Limits the number of samples to train (and validate\n",
      "                        and test) if set.\n",
      "  -b BATCH_SIZE, --batch_size BATCH_SIZE\n",
      "                        Batch size. Default value can be set in config file.\n",
      "                        Is doubled when no back propagation is done (while in\n",
      "                        eval mode). If a specific effective batch size is\n",
      "                        desired, set the eval_batch_size argument.\n",
      "  --eval_batch_size EVAL_BATCH_SIZE\n",
      "                        Batch size for evaluation. Overrides the effective\n",
      "                        batch size when evaluating.\n",
      "  -m {train,eval,eval_coco}, --mode {train,eval,eval_coco}\n",
      "                        Mode to launch the script in. Train: train model on\n",
      "                        speciffied folds. Eval: eval model on specified fold.\n",
      "                        Eval_coco: measures COCO metrics of specified fold\n",
      "  --fold [{train,val,test} ...]\n",
      "                        If training (mode=train): all folds entered here will\n",
      "                        be used for optimizing the network.If the train fold\n",
      "                        is selected and not the val fold, the val fold will be\n",
      "                        used during training to validate at each epoch.The\n",
      "                        most common scenario is to optimize on train and\n",
      "                        validate on val: select only train.When optimizing the\n",
      "                        network for the last time before test, we would like\n",
      "                        to optimize it on train + val: in that case select\n",
      "                        both train and val folds.Then for evaluation\n",
      "                        (mode=eval), we might want to evaluate on the val\n",
      "                        folds for hyper-parameter selection.And finally\n",
      "                        evaluate (mode=eval) on the test fold for the final\n",
      "                        predictions (and possibly metric) for the\n",
      "                        paper/competition\n",
      "  --max_epoch MAX_EPOCH\n",
      "                        Stop training when max_epoch is reached. If not set,\n",
      "                        value in config is used.\n",
      "  --eval_patch_size EVAL_PATCH_SIZE\n",
      "                        When evaluating, patch size the tile split into.\n",
      "  --eval_patch_overlap EVAL_PATCH_OVERLAP\n",
      "                        When evaluating, patch the tile with the specified\n",
      "                        overlap to reduce edge artifacts when reconstructing\n",
      "                        the whole tile\n",
      "  --master_addr MASTER_ADDR\n",
      "                        Address of master node\n",
      "  --master_port MASTER_PORT\n",
      "                        Port on master node\n",
      "  -n N, --nodes N       Number of total nodes\n",
      "  -g GPUS, --gpus GPUS  Number of gpus per node\n",
      "  -nr NR, --nr NR       Ranking within the nodes\n"
     ]
    }
   ],
   "source": [
    "! cd .. && python ./main.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffda5178",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5706bcff",
   "metadata": {},
   "source": [
    "An example use is for training a model with a certain config file, like so: \n",
    "python main.py --config configs/config.mapping_dataset.unet_resnet101_pretrained \n",
    "\n",
    "which will train the Unet-Resnet101 on the CrowdAI Mapping Challenge dataset. The batch size can be adjusted like so: \n",
    "\n",
    "python main.py --config configs/config.mapping_dataset.unet_resnet101_pretrained -b <new batch size>\n",
    "\n",
    "When training is done, the script can be launched in eval mode, to evaluate the trained model: \n",
    "    \n",
    "python main.py --config configs/config.mapping_dataset.unet_resnet101_pretrained --mode eval\n",
    "    \n",
    "Depending on the eval parameters of the config file, running this will output results on the test dataset.\n",
    "\n",
    "Finally, if you wish to compute AP and AR metrics with the COCO API, you can run: \n",
    "    \n",
    "python main.py --config configs/config.mapping_dataset.unet_resnet101_pretrained --mode eval_coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b02dc102",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T06:49:20.907128Z",
     "start_time": "2024-08-23T06:49:06.439844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mTraining on fold(s): ['train']\u001b[0m\n",
      "\u001b[94mINFO: Loading defaults from configs/config.defaults.mapping_dataset.json\u001b[0m\n",
      "\u001b[94m\tINFO: Loading defaults from configs/config.defaults.json\u001b[0m\n",
      "\u001b[94m\t\t\tINFO: Loading defaults from configs/loss_params.json\u001b[0m\n",
      "\u001b[94m\t\t\tINFO: Loading defaults from configs/optim_params.json\u001b[0m\n",
      "\u001b[94m\t\t\tINFO: Loading defaults from configs/polygonize_params.json\u001b[0m\n",
      "\u001b[94m\t\tINFO: Loading defaults from configs/dataset_params.mapping_dataset.json\u001b[0m\n",
      "\u001b[94m\t\tINFO: Loading defaults from configs/eval_params.mapping_dataset.json\u001b[0m\n",
      "\u001b[94m\t\t\tINFO: Loading defaults from configs/eval_params.defaults.json\u001b[0m\n",
      "\u001b[94m\tINFO: Loading defaults from configs/backbone_params.unet_resnet101.json\u001b[0m\n",
      "\u001b[94mGPU 0 -> Ready. There are 0 GPU(s) available on this node.\u001b[0m\n",
      "\u001b[91mGPU 0 -> ERROR: Data root directory amongst \"['/data/titane/user/nigirard/data/mapping_challenge_dataset', '/Users/younes.abid/data/mapping_challenge_dataset', '/data/mapping_challenge_dataset']\" not found!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! cd .. && python main.py --config configs/config.mapping_dataset.unet_resnet101_pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0618829",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T07:13:30.178755Z",
     "start_time": "2024-08-23T07:13:30.164050Z"
    }
   },
   "source": [
    "# Download trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab19faac",
   "metadata": {},
   "source": [
    "https://drive.google.com/drive/folders/1poTQbpCz12ra22CsucF_hd_8dSQ1T3eT?usp=sharing."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d66a77ff",
   "metadata": {},
   "source": [
    "You should then place those runs in a folder named \"runs\" inside the \"frame_field_learning\" folder like so:\n",
    "\n",
    "Polygonization-by-Frame-Field-Learning\n",
    "|-- frame_field_learning\n",
    "|   |-- runs\n",
    "|   |   |-- inria_dataset_polygonized.unet_resnet101_pretrained.leaderboard | 2020-06-02 07:57:31\n",
    "|   |   |-- mapping_dataset.unet_resnet101_pretrained.field_off.train_val | 2020-09-07 11:54:48\n",
    "|   |   |-- mapping_dataset.unet_resnet101_pretrained.train_val | 2020-09-07 11:28:51\n",
    "|   |   `-- ...\n",
    "|   |-- inference.py\n",
    "|   `-- ...\n",
    "|-- main.py\n",
    "|-- README.md (this file)\n",
    "`-- ...\n",
    "\n",
    "Because Google Drive reformats folder names, you have to rename the run folders as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "42a84640",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T08:30:11.758533Z",
     "start_time": "2024-08-23T08:30:10.585537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: Error opening archive: Unrecognized archive format\r\n"
     ]
    }
   ],
   "source": [
    "!  cd \"./git/Polygonization-by-Frame-Field-Learning/frame_field_learning/runs/mapping_dataset.unet_resnet101_pretrained.train_val _ 2020-09-07 11_28_51/checkpoints/\" && \\\n",
    "tar -xvf checkpoint.best_val.epoch_000047.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "13719bbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T08:29:29.281224Z",
     "start_time": "2024-08-23T08:29:29.011426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint.best_val.epoch_000047.tar\r\n"
     ]
    }
   ],
   "source": [
    "ls \"./git/Polygonization-by-Frame-Field-Learning/frame_field_learning/runs/mapping_dataset.unet_resnet101_pretrained.train_val _ 2020-09-07 11_28_51/checkpoints/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50cc8374",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T08:27:17.420984Z",
     "start_time": "2024-08-23T08:27:17.410472Z"
    }
   },
   "outputs": [],
   "source": [
    "# open  '/Users/younes.abid/Desktop/inference_test/train/building detection/git/Polygonization-by-Frame-Field-Learning/lydorn_utils/lydorn_utils/run_utils.py' \n",
    "#put this function in line 537\n",
    "# put this on line 582\n",
    "    # if run_name and \"|\" not in run_name:\n",
    "        # run_name = reformat_file_name(run_name)\n",
    "def reformat_file_name(path):\n",
    "    \"\"\"\n",
    "    Reformats the file name to replace certain underscores with colons and a single space with a pipe in the timestamp.\n",
    "    Specifically targets the format:\n",
    "    'mapping_dataset.unet_resnet101_pretrained.train_val _ 2020-09-07 11_28_51'\n",
    "    to transform it into:\n",
    "    'mapping_dataset.unet_resnet101_pretrained.train_val | 2020-09-07 11:28:51'\n",
    "    \"\"\"\n",
    "    import os\n",
    "    dir_path, file_name = os.path.split(path)\n",
    "    \n",
    "    # Identify the base and date parts based on the expected format ending with ' _ YYYY-MM-DD HH_MM_SS'\n",
    "    if ' _ ' in file_name:\n",
    "        # Split at the specific ' _ ' sequence that precedes the date\n",
    "        base_part, date_time_part = file_name.split(' _ ', 1)\n",
    "\n",
    "        # Replace underscores in the date-time part with colons where they represent time\n",
    "        date_part, time_part = date_time_part.split(' ')\n",
    "        time_part = time_part.replace('_', ':', 2)\n",
    "\n",
    "        # Assemble the new file name with a properly trimmed pipe symbol\n",
    "        file_name = f\"{base_part.strip()} | {date_part} {time_part}\"\n",
    "\n",
    "    return os.path.join(dir_path, file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31a2d63b-b697-42ce-aad3-aac5620a4936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix this function this way\n",
    "def setup_run_dir(runs_dirpath, run_name=None, new_run=False, check_exists=False):\n",
    "    \"\"\"\n",
    "    If new_run is True, creates a new directory:\n",
    "        If run_name is None, generate a random name\n",
    "        else build the created directory name with run_name\n",
    "\n",
    "    If new_run is False, return an existing directory:\n",
    "        if run_name is None, return the last created directory (from timestamp)\n",
    "        else return the last created directory (from timestamp) whose name starts with run_name,\n",
    "        if that does not exist and check_exists is False create a new run with run_name,\n",
    "        if check_exists is True, then raise an error.\n",
    "\n",
    "    Special case: if there is no existing runs, the new_run is not taken into account and the function behaves like new_run is True.\n",
    "\n",
    "    :param runs_dirpath: Parent directory path of all the runs\n",
    "    :param run_name:\n",
    "    :param new_run:\n",
    "    :param check_exists:\n",
    "    :return: Run directory path. The directory name is in the form \"run_name | timestamp\"\n",
    "    \"\"\"\n",
    "    #B_FIX\n",
    "    # if run_name and \"|\" not in run_name:\n",
    "    #     run_name = reformat_file_name(run_name)\n",
    "    #E_FIX\n",
    "    # Create runs directory of it does not exist\n",
    "    if not os.path.exists(runs_dirpath):\n",
    "        os.makedirs(runs_dirpath, exist_ok=True)\n",
    "\n",
    "    existing_run_dirnames = os.listdir(runs_dirpath)\n",
    "    print(existing_run_dirnames)\n",
    "    if new_run or (not new_run and not 0 < len(existing_run_dirnames)):\n",
    "        if run_name is not None:\n",
    "            # Create another directory name for the run, with its name starting with run_name\n",
    "            name_timestamped = create_name_timestamped(run_name)\n",
    "        else:\n",
    "            # Create another directory name for the run, excluding the existing names\n",
    "            existing_run_names = [existing_run_dirname.split(\" | \")[0] for existing_run_dirname in\n",
    "                                  existing_run_dirnames]\n",
    "            name_timestamped = create_free_name_timestamped(exclude_list=existing_run_names)\n",
    "        current_run_dirpath = os.path.join(runs_dirpath, name_timestamped)\n",
    "        os.mkdir(current_run_dirpath)\n",
    "    else:\n",
    "        if run_name is not None:\n",
    "            # Pick run dir based on run_name\n",
    "            #B_FIX\n",
    "            filtered_existing_run_dirnames = [existing_run_dirname for existing_run_dirname in existing_run_dirnames if\n",
    "                                              existing_run_dirname.split(\" _ \")[0] == run_name]\n",
    "            \n",
    "            # filtered_existing_run_dirnames = [existing_run_dirname for existing_run_dirname in existing_run_dirnames if\n",
    "            #                                   existing_run_dirname.split(\" | \")[0] == run_name]\n",
    "            #E_FIX\n",
    "            if filtered_existing_run_dirnames:\n",
    "                #B_FIX\n",
    "                filtered_existing_run_timestamps = [filtered_existing_run_dirname.split(\" _ \")[1] for\n",
    "                                                    filtered_existing_run_dirname in\n",
    "                                                    filtered_existing_run_dirnames]\n",
    "                # filtered_existing_run_timestamps = [filtered_existing_run_dirname.split(\" | \")[1] for\n",
    "                #                                     filtered_existing_run_dirname in\n",
    "                #                                     filtered_existing_run_dirnames]\n",
    "                #E_FIX\n",
    "                filtered_last_index = filtered_existing_run_timestamps.index(max(filtered_existing_run_timestamps))\n",
    "                current_run_dirname = filtered_existing_run_dirnames[filtered_last_index]\n",
    "            else:\n",
    "                if check_exists:\n",
    "                    raise FileNotFoundError(\"Run '{}' does not exist.\".format(run_name))\n",
    "                else:\n",
    "                    return setup_run_dir(runs_dirpath, run_name=run_name, new_run=True)\n",
    "        else:\n",
    "            # Pick last run dir based on timestamp\n",
    "            #B_FIX\n",
    "            existing_run_timestamps = [existing_run_dirname.split(\" _ \")[1] for existing_run_dirname in\n",
    "                                       existing_run_dirnames]\n",
    "            # existing_run_timestamps = [existing_run_dirname.split(\" | \")[1] for existing_run_dirname in\n",
    "            #                            existing_run_dirnames]\n",
    "            #E_FIX\n",
    "            last_index = existing_run_timestamps.index(max(existing_run_timestamps))\n",
    "            current_run_dirname = existing_run_dirnames[last_index]\n",
    "        current_run_dirpath = os.path.join(runs_dirpath, current_run_dirname)\n",
    "    return current_run_dirpath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a34d14ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T08:56:07.699278Z",
     "start_time": "2024-08-23T08:56:07.687438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mapping_dataset.unet_resnet101_pretrained.train_val | 2020-09-07 11:28:51'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/Users/younes.abid/Desktop/inference_test/train/building_detection/git/Polygonization-by-Frame-Field-Learning/frame_field_learning/runs/mapping_dataset.unet_resnet101_pretrained.train_val _ 2020-09-07 11_28_51\"\n",
    "path = \"mapping_dataset.unet_resnet101_pretrained.train_val _ 2020-09-07 11_28_51\"\n",
    "reformat_file_name(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ac8230c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T08:58:28.144564Z",
     "start_time": "2024-08-23T08:58:27.865423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: /Users/younes.abid/Desktop/inference_test/train/building detection/git/Polygonization-by-Frame-Field-Learning/data/building detection model/data/mapping_challenge_dataset/raw/val/images/000000000000.jpg: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "ls \"/Users/younes.abid/Desktop/inference_test/train/building detection/git/Polygonization-by-Frame-Field-Learning/data/building detection model/data/mapping_challenge_dataset/raw/val/images/000000000000.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c922e71e",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8bf86374",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T07:10:56.502464Z",
     "start_time": "2024-08-23T07:10:56.486665Z"
    }
   },
   "source": [
    "Make sure the run folder has the correct structure:\n",
    "\n",
    "Polygonization-by-Frame-Field-Learning\n",
    "|-- frame_field_learning\n",
    "|   |-- runs\n",
    "|   |   |-- <run_name> | <yyyy-mm-dd hh:mm:ss>\n",
    "|   |   `-- ...\n",
    "|   |-- inference.py\n",
    "|   `-- ...\n",
    "|-- main.py\n",
    "|-- README.md (this file)\n",
    "`-- ..."
   ]
  },
  {
   "cell_type": "raw",
   "id": "47b7c8d6",
   "metadata": {},
   "source": [
    "Execute the [main.py] script like so (filling values for arguments run_name and in_filepath): python main.py --run_name <run_name> --in_filepath <your_image_filepath>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cde2637-895b-4448-a712-a23d7e6db8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: /Users/younes.abid/Desktop/inference_test/train/building detection/git/Polygonization-by-Frame-Field-Learning/frame_field_learning/runs/: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "ls -l \"/Users/younes.abid/Desktop/inference_test/train/building detection/git/Polygonization-by-Frame-Field-Learning/frame_field_learning/runs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3529e480-02e4-4dcb-9e89-bbce5e5a7642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.json    \u001b[34mcheckpoints\u001b[m\u001b[m/ config.json\n"
     ]
    }
   ],
   "source": [
    "ls '/Users/younes.abid/Desktop/inference_test/train/building detection/git/Polygonization-by-Frame-Field-Learning/frame_field_learning/runs/mapping_dataset.unet_resnet101_pretrained.train_val _ 2020-09-07 11_28_51'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05a985a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T09:09:29.989171Z",
     "start_time": "2024-08-23T09:08:52.808158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mERROR: Run 'mapping_dataset.unet_resnet101_pretrained.train_val' does not exist.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! cd .. && python main.py \\\n",
    "--runs_dirpath \"/Users/younes.abid/Desktop/inference_test/train/building_detection/git/Polygonization-by-Frame-Field-Learning/frame_field_learning/runs/\" \\\n",
    "--run_name \"mapping_dataset.unet_resnet101_pretrained.train_val\" \\\n",
    "--in_filepath \"/Users/younes.abid/Desktop/inference_test/train/building_detection/git/Polygonization-by-Frame-Field-Learning/data/building detection model/data/mapping_challenge_dataset/raw/val/images/000000000000.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df4ddbfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T09:08:35.972353Z",
     "start_time": "2024-08-23T09:08:33.697706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import osgeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b25355f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T09:08:37.959470Z",
     "start_time": "2024-08-23T09:08:35.974122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: GDAL==3.6.2 in /Users/younes.abid/opt/anaconda3/envs/building-detection/lib/python3.10/site-packages (3.6.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install GDAL==3.6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "273b1ee0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T09:06:10.395143Z",
     "start_time": "2024-08-23T09:06:09.317031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rasterio                  1.3.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list |grep rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9321d071",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T09:03:32.880121Z",
     "start_time": "2024-08-23T09:02:58.699439Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/younes.abid/opt/anaconda3/envs/building-detection\n",
      "\n",
      "  added / updated specs:\n",
      "    - rasterio==1.3.10\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  affine             pkgs/main/noarch::affine-2.3.0-pyhd3eb1b0_0 \n",
      "  attrs              pkgs/main/osx-64::attrs-23.1.0-py310hecd8cb5_0 \n",
      "  blas               pkgs/main/osx-64::blas-1.0-mkl \n",
      "  blosc              pkgs/main/osx-64::blosc-1.21.3-hcec6c5f_0 \n",
      "  boost-cpp          pkgs/main/osx-64::boost-cpp-1.82.0-ha357a0b_2 \n",
      "  c-ares             pkgs/main/osx-64::c-ares-1.19.1-h6c40b1e_0 \n",
      "  cairo              pkgs/main/osx-64::cairo-1.16.0-h3ce6f7e_5 \n",
      "  certifi            pkgs/main/osx-64::certifi-2024.7.4-py310hecd8cb5_0 \n",
      "  cfitsio            pkgs/main/osx-64::cfitsio-3.470-hbd21bf8_7 \n",
      "  click              pkgs/main/osx-64::click-8.1.7-py310hecd8cb5_0 \n",
      "  click-plugins      pkgs/main/noarch::click-plugins-1.1.1-pyhd3eb1b0_0 \n",
      "  cligj              pkgs/main/noarch::cligj-0.7.2-pyhd3eb1b0_0 \n",
      "  expat              pkgs/main/osx-64::expat-2.6.2-hcec6c5f_0 \n",
      "  fontconfig         pkgs/main/osx-64::fontconfig-2.14.1-hb0a0c50_2 \n",
      "  freetype           pkgs/main/osx-64::freetype-2.12.1-hd8bbffd_0 \n",
      "  freexl             pkgs/main/osx-64::freexl-1.0.6-h9ed2024_0 \n",
      "  geos               pkgs/main/osx-64::geos-3.8.0-hb1e8313_0 \n",
      "  geotiff            pkgs/main/osx-64::geotiff-1.7.0-hf6ff7a4_1 \n",
      "  gettext            pkgs/main/osx-64::gettext-0.21.0-he85b6c0_1 \n",
      "  giflib             pkgs/main/osx-64::giflib-5.2.1-h6c40b1e_3 \n",
      "  glib               pkgs/main/osx-64::glib-2.78.4-hcec6c5f_0 \n",
      "  glib-tools         pkgs/main/osx-64::glib-tools-2.78.4-hcec6c5f_0 \n",
      "  hdf4               pkgs/main/osx-64::hdf4-4.2.13-h39711bb_2 \n",
      "  hdf5               pkgs/main/osx-64::hdf5-1.12.1-h2b2ad87_2 \n",
      "  icu                pkgs/main/osx-64::icu-73.1-hcec6c5f_0 \n",
      "  intel-openmp       pkgs/main/osx-64::intel-openmp-2023.1.0-ha357a0b_43548 \n",
      "  jpeg               pkgs/main/osx-64::jpeg-9e-h46256e1_3 \n",
      "  json-c             pkgs/main/osx-64::json-c-0.16-hca72f7f_0 \n",
      "  kealib             pkgs/main/osx-64::kealib-1.5.0-h72c422f_1 \n",
      "  krb5               pkgs/main/osx-64::krb5-1.20.1-hdba6334_1 \n",
      "  lcms2              pkgs/main/osx-64::lcms2-2.12-hf1fd2bf_0 \n",
      "  lerc               pkgs/main/osx-64::lerc-3.0-he9d5cce_0 \n",
      "  libboost           pkgs/main/osx-64::libboost-1.82.0-hf53b9f2_2 \n",
      "  libcurl            pkgs/main/osx-64::libcurl-8.2.1-ha585b31_0 \n",
      "  libcxx             pkgs/main/osx-64::libcxx-14.0.6-h9765a3e_0 \n",
      "  libdeflate         pkgs/main/osx-64::libdeflate-1.17-hb664fd8_1 \n",
      "  libedit            pkgs/main/osx-64::libedit-3.1.20230828-h6c40b1e_0 \n",
      "  libev              pkgs/main/osx-64::libev-4.33-h9ed2024_1 \n",
      "  libgdal            pkgs/main/osx-64::libgdal-3.6.2-h89d12a6_3 \n",
      "  libgfortran        pkgs/main/osx-64::libgfortran-5.0.0-11_3_0_hecd8cb5_28 \n",
      "  libgfortran5       pkgs/main/osx-64::libgfortran5-11.3.0-h9dfd629_28 \n",
      "  libglib            pkgs/main/osx-64::libglib-2.78.4-h19e1a8f_0 \n",
      "  libiconv           pkgs/main/osx-64::libiconv-1.16-h6c40b1e_3 \n",
      "  libkml             pkgs/main/osx-64::libkml-1.3.0-h85bf17e_7 \n",
      "  libnetcdf          pkgs/main/osx-64::libnetcdf-4.8.1-h9c0abef_4 \n",
      "  libnghttp2         pkgs/main/osx-64::libnghttp2-1.52.0-h1c88b7d_1 \n",
      "  libpng             pkgs/main/osx-64::libpng-1.6.39-h6c40b1e_0 \n",
      "  libpq              pkgs/main/osx-64::libpq-12.15-hdb2fb19_1 \n",
      "  libspatialite      pkgs/main/osx-64::libspatialite-4.3.0a-hd1e8275_23 \n",
      "  libssh2            pkgs/main/osx-64::libssh2-1.10.0-hdb2fb19_2 \n",
      "  libtiff            pkgs/main/osx-64::libtiff-4.5.1-hcec6c5f_0 \n",
      "  libwebp-base       pkgs/main/osx-64::libwebp-base-1.3.2-h6c40b1e_0 \n",
      "  libxml2            pkgs/main/osx-64::libxml2-2.10.4-h45904e2_2 \n",
      "  libzip             pkgs/main/osx-64::libzip-1.8.0-h272c8d6_0 \n",
      "  llvm-openmp        pkgs/main/osx-64::llvm-openmp-14.0.6-h0dcd299_0 \n",
      "  lz4-c              pkgs/main/osx-64::lz4-c-1.9.4-hcec6c5f_1 \n",
      "  mkl                pkgs/main/osx-64::mkl-2023.1.0-h8e150cf_43560 \n",
      "  mkl-service        pkgs/main/osx-64::mkl-service-2.4.0-py310h6c40b1e_1 \n",
      "  mkl_fft            pkgs/main/osx-64::mkl_fft-1.3.8-py310h6c40b1e_0 \n",
      "  mkl_random         pkgs/main/osx-64::mkl_random-1.2.4-py310ha357a0b_0 \n",
      "  nspr               pkgs/main/osx-64::nspr-4.35-hcec6c5f_0 \n",
      "  nss                pkgs/main/osx-64::nss-3.89.1-hcec6c5f_0 \n",
      "  numpy              pkgs/main/osx-64::numpy-1.26.4-py310h827a554_0 \n",
      "  numpy-base         pkgs/main/osx-64::numpy-base-1.26.4-py310ha186be2_0 \n",
      "  openjpeg           pkgs/main/osx-64::openjpeg-2.5.2-hbf2204d_0 \n",
      "  pcre2              pkgs/main/osx-64::pcre2-10.42-h9b97e30_1 \n",
      "  pixman             pkgs/main/osx-64::pixman-0.40.0-h9ed2024_1 \n",
      "  poppler            pkgs/main/osx-64::poppler-22.12.0-ha8a1649_3 \n",
      "  poppler-data       pkgs/main/osx-64::poppler-data-0.4.11-hecd8cb5_1 \n",
      "  proj               pkgs/main/osx-64::proj-6.2.1-hfd5b9e3_0 \n",
      "  pyparsing          pkgs/main/osx-64::pyparsing-3.0.9-py310hecd8cb5_0 \n",
      "  qhull              pkgs/main/osx-64::qhull-2020.2-ha357a0b_2 \n",
      "  rasterio           pkgs/main/osx-64::rasterio-1.3.10-py310h3a73f4b_0 \n",
      "  snuggs             pkgs/main/noarch::snuggs-1.4.7-pyhd3eb1b0_0 \n",
      "  tbb                pkgs/main/osx-64::tbb-2021.8.0-ha357a0b_0 \n",
      "  tiledb             pkgs/main/osx-64::tiledb-2.3.3-h74f4c1e_2 \n",
      "  uriparser          pkgs/main/osx-64::uriparser-0.9.7-h6c40b1e_0 \n",
      "  xerces-c           pkgs/main/osx-64::xerces-c-3.2.4-hcec6c5f_1 \n",
      "  zstd               pkgs/main/osx-64::zstd-1.5.5-hc035e20_2 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "! conda install rasterio==1.3.10 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cd22250",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T06:26:42.017551Z",
     "start_time": "2024-08-26T06:26:42.008788Z"
    }
   },
   "outputs": [],
   "source": [
    "JVM_MEMORY_BASE = 10  # in GB\n",
    "ADDITIONAL_TOOL_MEMORY = 10  # in GB\n",
    "MAX_MEMORY = 40 # in GB\n",
    "\n",
    "def calculate_total_memory(image_size_1, image_size_2, AOI_percentage):\n",
    "    total_zip_files_size = image_size_1 + image_size_2\n",
    "    JVM_memory_work = round(total_zip_files_size) * AOI_percentage * 5\n",
    "    JVM_memory = JVM_MEMORY_BASE + JVM_memory_work\n",
    "    total_memory = min(JVM_memory + ADDITIONAL_TOOL_MEMORY, MAX_MEMORY)\n",
    "    return total_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac18b262",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T06:27:23.744914Z",
     "start_time": "2024-08-26T06:27:23.738124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_total_memory(0.4, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76c5ff2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T06:27:17.176412Z",
     "start_time": "2024-08-26T06:27:17.164604Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_total_memory(0.8, 0.5, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac2e619a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T08:36:40.602681Z",
     "start_time": "2024-08-28T08:36:40.590522Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "log_entry = \"\"\"\n",
    "docker-compose-inference-worker-1 | [INFO] 2024-08-28 08:20:26,362: [inferenceworker.worker] -> [run_inference]: younes 247 ---------------------------------------------------------------------------------------------------- \n",
    "job=Job(id='1') request=RequestDetectionStrict(resolution_default=0.5, resolution_minimum=0.1, resolution_maximum=5.0, file_url='/data/video_frames/tmp35fdz0wi/frame_150.jpg', is_geotiff=False, aoi=None, confidence_threshold=0.25, nms_threshold=0.45) model=ModelVideoObjectDetection(resolution_default=0.5, resolution_minimum=0.1, resolution_maximum=5.0, activation='None', id='fish_recognition_latest', version='1', date='2024-08-26', description='YOLOv5 object detector and classifier trained on fish data', labels=['fish'], family='yolov5', type=<ModelType.video: 'FULL_MOTION_VIDEO'>, inputs=[ModelInput(dtype=<Dtypes.FLOAT32: 'float32'>, shape=(3, 640, 640))], preprocessing_filters=[], job_type='video_object_detection', tile_size=640, channel_first=True, padding=16, preprocessing_mask=None, postprocessing_filter=None, efficientdet_config={}, confidence_threshold=0.25, nms_threshold=0.45, classifier=ModelClassification(resolution_default=0.5, resolution_minimum=0.1, resolution_maximum=5.0, activation='None', id='fish_classifier_latest', version='1', date='2024-08-26', description='EfficientNet classifier for fish species', labels=['Bristlenose_catfish', 'Gold', 'Guppy', 'Jacks', 'Paradise Fish', 'Red_tail_black_shark', 'Sea Horse Fish', 'angel_fish', 'bala', 'barracuda', 'butterfly_fish', 'cichild', 'clown', 'crab', 'damsel_fishes', 'dolphin', 'eel', 'groupers', 'hatchetfish', 'jellyfish', 'king_fish', 'lion', 'luderick', 'neon tetra', 'octopus', 'penguins', 'porkfish', 'puffer', 'sail_fish', 'sea cow', 'seal', 'shark', 'shrimp', 'snappers', 'squid', 'starfish', 'stingray', 'surgeon_fish', 'sword_fish', 'tuna', 'turtle_tortoise', 'unknown', 'wrasse', 'zebra', 'zebra loach'], family='classification', type=<ModelType.video: 'FULL_MOTION_VIDEO'>, inputs=[ModelInput(dtype=<Dtypes.FLOAT32: 'float32'>, shape=(3, 128, 128))], preprocessing_filters=[], job_type='classification', tile_size=128, channel_first=True, padding=16, preprocessing_mask=None, postprocessing_filter=None, efficientdet_config={}, confidence_threshold=0.1, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\"\"\"\n",
    "\n",
    "# Simple regex to match and extract log message\n",
    "pattern = r\"(?<=\\-\\-\\>).*\"\n",
    "matches = re.findall(pattern, log_entry, re.DOTALL)\n",
    "\n",
    "for match in matches:\n",
    "    print(\"Log Message:\")\n",
    "    print(match.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3149f693",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T08:36:47.427790Z",
     "start_time": "2024-08-28T08:36:47.408108Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146e7a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "building-detection",
   "language": "python",
   "name": "building-detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "965.455px",
    "left": "1464px",
    "top": "0px",
    "width": "271.634px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
